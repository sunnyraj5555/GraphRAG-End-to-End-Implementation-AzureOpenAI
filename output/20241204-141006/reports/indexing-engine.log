14:10:06,727 graphrag.config.read_dotenv INFO Loading pipeline .env file
14:10:06,743 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 32",
        "type": "azure_openai_chat",
        "model": "gpt-4o",
        "max_tokens": 4000,
        "request_timeout": 180.0,
        "api_base": "https://cognisearch.openai.azure.com/",
        "api_version": "2024-02-15-preview",
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": "gpt-4o",
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": ".",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://cognisearch.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "text-embedding-3-small",
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://cognisearch.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://cognisearch.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://cognisearch.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://cognisearch.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
14:10:06,766 graphrag.index.create_pipeline_config INFO skipping workflows 
14:10:06,769 graphrag.index.run INFO Running pipeline
14:10:06,769 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at output\20241204-141006\artifacts
14:10:06,772 graphrag.index.input.load_input INFO loading input from root_dir=input
14:10:06,772 graphrag.index.input.load_input INFO using file storage for input
14:10:06,777 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
14:10:06,779 graphrag.index.input.text INFO found text files from input, found [('book.txt', {})]
14:10:06,793 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
14:10:06,794 graphrag.index.run INFO Final # of rows loaded: 1
14:10:06,985 graphrag.index.run INFO Running workflow: create_base_text_units...
14:10:06,986 graphrag.index.run INFO dependencies for create_base_text_units: []
14:10:06,997 datashaper.workflow.workflow INFO executing verb orderby
14:10:07,5 datashaper.workflow.workflow INFO executing verb zip
14:10:07,15 datashaper.workflow.workflow INFO executing verb aggregate_override
14:10:07,35 datashaper.workflow.workflow INFO executing verb chunk
14:10:07,795 datashaper.workflow.workflow INFO executing verb select
14:10:07,810 datashaper.workflow.workflow INFO executing verb unroll
14:10:07,829 datashaper.workflow.workflow INFO executing verb rename
14:10:07,843 datashaper.workflow.workflow INFO executing verb genid
14:10:07,879 datashaper.workflow.workflow INFO executing verb unzip
14:10:07,899 datashaper.workflow.workflow INFO executing verb copy
14:10:07,919 datashaper.workflow.workflow INFO executing verb filter
14:10:07,961 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
14:10:08,280 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
14:10:08,280 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
14:10:08,282 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
14:10:08,342 datashaper.workflow.workflow INFO executing verb entity_extract
14:10:08,406 graphrag.llm.openai.create_openai_client INFO Creating Azure OpenAI client api_base=https://cognisearch.openai.azure.com, deployment_name=gpt-4o
14:10:09,229 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o: TPM=0, RPM=0
14:10:09,229 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o: 25
14:10:14,577 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:14,592 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.10899999999674. input_tokens=2235, output_tokens=112
14:10:14,668 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:14,671 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.14000000001397. input_tokens=2233, output_tokens=144
14:10:15,415 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:15,418 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.922000000020489. input_tokens=2234, output_tokens=221
14:10:15,494 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:15,497 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.0. input_tokens=2234, output_tokens=214
14:10:15,680 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:15,686 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.047000000020489. input_tokens=2234, output_tokens=311
14:10:15,823 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:15,827 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.26600000000326. input_tokens=2234, output_tokens=269
14:10:16,160 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:16,163 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.75. input_tokens=2232, output_tokens=292
14:10:16,179 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:16,183 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.7189999999827705. input_tokens=2233, output_tokens=382
14:10:16,673 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:16,676 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.2810000000172295. input_tokens=2233, output_tokens=363
14:10:16,791 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:16,796 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.35899999999674. input_tokens=2234, output_tokens=427
14:10:16,893 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:16,896 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.327999999979511. input_tokens=2234, output_tokens=276
14:10:16,973 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:16,979 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.6560000000172295. input_tokens=2233, output_tokens=491
14:10:17,524 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:17,529 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.077999999979511. input_tokens=2233, output_tokens=394
14:10:18,139 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:18,142 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.561999999976251. input_tokens=2234, output_tokens=352
14:10:18,247 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:18,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.702999999979511. input_tokens=2234, output_tokens=266
14:10:18,615 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:18,621 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.98399999999674. input_tokens=2234, output_tokens=392
14:10:18,866 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:18,873 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.530999999959022. input_tokens=2234, output_tokens=425
14:10:19,117 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:19,124 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.530999999959022. input_tokens=2231, output_tokens=340
14:10:19,440 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:19,444 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.938000000023749. input_tokens=2234, output_tokens=230
14:10:19,693 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:19,702 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.10999999998603. input_tokens=2234, output_tokens=364
14:10:19,818 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:19,820 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.6410000000032596. input_tokens=2233, output_tokens=172
14:10:19,901 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:19,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.452999999979511. input_tokens=2234, output_tokens=627
14:10:19,924 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:19,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.327999999979511. input_tokens=2234, output_tokens=544
14:10:20,7 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:20,12 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.8439999999827705. input_tokens=2234, output_tokens=233
14:10:20,282 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:20,285 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.672000000020489. input_tokens=2234, output_tokens=452
14:10:20,331 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:20,335 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.51500000001397. input_tokens=2234, output_tokens=231
14:10:20,429 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:20,433 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.75. input_tokens=2234, output_tokens=390
14:10:21,19 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:21,22 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.125. input_tokens=2233, output_tokens=373
14:10:21,107 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:21,111 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.436999999976251. input_tokens=2234, output_tokens=227
14:10:21,191 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:21,193 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.672000000020489. input_tokens=2232, output_tokens=219
14:10:21,343 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:21,349 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.860000000044238. input_tokens=2234, output_tokens=399
14:10:21,398 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:21,401 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.73499999998603. input_tokens=2234, output_tokens=435
14:10:21,511 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:21,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.25. input_tokens=2233, output_tokens=155
14:10:21,700 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:21,705 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.8280000000377186. input_tokens=2234, output_tokens=203
14:10:21,952 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:21,954 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.3290000000270084. input_tokens=2234, output_tokens=226
14:10:22,15 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:22,18 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.8910000000032596. input_tokens=2234, output_tokens=130
14:10:23,215 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:23,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.76500000001397. input_tokens=2234, output_tokens=181
14:10:23,381 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:23,384 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.5619999999762513. input_tokens=2233, output_tokens=276
14:10:23,430 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:23,433 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.64100000000326. input_tokens=2234, output_tokens=307
14:10:24,58 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:24,61 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.35899999999674. input_tokens=2234, output_tokens=128
14:10:24,106 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:24,109 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.672000000020489. input_tokens=2234, output_tokens=306
14:10:24,372 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:24,377 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.6719999999622814. input_tokens=2234, output_tokens=140
14:10:24,417 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:24,421 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 15.03100000001723. input_tokens=2234, output_tokens=827
14:10:24,574 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:24,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.64100000000326. input_tokens=2234, output_tokens=293
14:10:24,930 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:24,933 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.922000000020489. input_tokens=2234, output_tokens=269
14:10:25,110 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:25,112 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:25,116 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.155999999959022. input_tokens=2234, output_tokens=148
14:10:25,118 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.6089999999967404. input_tokens=2232, output_tokens=152
14:10:25,144 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:25,150 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.125. input_tokens=2234, output_tokens=141
14:10:25,179 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:25,223 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.203000000037719. input_tokens=2233, output_tokens=282
14:10:25,250 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:25,258 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.8589999999967404. input_tokens=2233, output_tokens=177
14:10:25,377 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:25,382 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.4689999999827705. input_tokens=2235, output_tokens=405
14:10:25,977 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:25,980 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.625. input_tokens=2234, output_tokens=221
14:10:26,183 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:26,187 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.89100000000326. input_tokens=2234, output_tokens=369
14:10:26,291 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:26,296 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.875. input_tokens=2234, output_tokens=550
14:10:26,312 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:26,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.10999999998603. input_tokens=2234, output_tokens=133
14:10:26,386 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:26,388 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 17.0. input_tokens=2234, output_tokens=693
14:10:27,500 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:27,504 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 18.14100000000326. input_tokens=2235, output_tokens=702
14:10:27,546 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:27,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.125. input_tokens=2234, output_tokens=253
14:10:27,764 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:27,766 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.780999999959022. input_tokens=2234, output_tokens=777
14:10:27,777 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:27,781 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.39100000000326. input_tokens=2235, output_tokens=228
14:10:27,832 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:27,836 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.5. input_tokens=2234, output_tokens=322
14:10:28,152 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:28,156 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.952999999979511. input_tokens=2234, output_tokens=390
14:10:28,475 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:28,478 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.422000000020489. input_tokens=2233, output_tokens=325
14:10:29,135 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:29,138 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.75. input_tokens=2234, output_tokens=373
14:10:29,561 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:29,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.438000000023749. input_tokens=2233, output_tokens=367
14:10:29,686 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:29,690 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.282000000006519. input_tokens=2234, output_tokens=363
14:10:29,958 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:29,961 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.562000000034459. input_tokens=2234, output_tokens=364
14:10:30,81 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:30,84 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.828000000037719. input_tokens=2234, output_tokens=300
14:10:30,475 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:30,478 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.9060000000172295. input_tokens=2234, output_tokens=291
14:10:30,550 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:30,553 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.625. input_tokens=2234, output_tokens=438
14:10:30,760 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:30,776 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.625. input_tokens=2235, output_tokens=330
14:10:30,863 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:30,870 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.75. input_tokens=2234, output_tokens=501
14:10:30,886 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:30,892 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 12.75. input_tokens=2234, output_tokens=139
14:10:31,369 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:31,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.25. input_tokens=2234, output_tokens=486
14:10:32,16 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:32,18 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.4689999999827705. input_tokens=2234, output_tokens=300
14:10:32,54 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:32,59 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.2810000000172295. input_tokens=2234, output_tokens=273
14:10:32,115 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:32,128 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.952999999979511. input_tokens=2234, output_tokens=448
14:10:32,148 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:32,154 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.171999999962281. input_tokens=2234, output_tokens=363
14:10:32,221 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:32,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.0. input_tokens=2234, output_tokens=406
14:10:32,574 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:32,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.75. input_tokens=2234, output_tokens=345
14:10:32,823 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:32,830 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.3439999999827705. input_tokens=2233, output_tokens=306
14:10:33,33 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:33,38 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.4679999999934807. input_tokens=2234, output_tokens=239
14:10:33,102 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:33,107 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.594000000040978. input_tokens=2234, output_tokens=370
14:10:33,273 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:33,281 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.577999999979511. input_tokens=2234, output_tokens=259
14:10:33,544 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:33,549 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.438000000023749. input_tokens=2234, output_tokens=514
14:10:33,688 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:33,691 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.73499999998603. input_tokens=2234, output_tokens=331
14:10:34,123 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:34,130 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.1089999999967404. input_tokens=2234, output_tokens=124
14:10:34,267 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:34,271 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.48499999998603. input_tokens=2234, output_tokens=525
14:10:34,374 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:34,378 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.6089999999967404. input_tokens=2233, output_tokens=258
14:10:34,718 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:34,723 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.672000000020489. input_tokens=2234, output_tokens=204
14:10:34,970 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:34,979 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.078000000037719. input_tokens=2235, output_tokens=213
14:10:35,183 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:35,190 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.1570000000065193. input_tokens=2234, output_tokens=83
14:10:35,306 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:35,309 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.172000000020489. input_tokens=2233, output_tokens=419
14:10:35,513 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:35,520 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.657000000006519. input_tokens=2234, output_tokens=293
14:10:35,598 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:35,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.125. input_tokens=2234, output_tokens=395
14:10:35,625 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:35,631 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.23399999999674. input_tokens=2234, output_tokens=586
14:10:36,272 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:36,281 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.125. input_tokens=2234, output_tokens=379
14:10:36,427 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:36,432 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.10899999999674. input_tokens=2234, output_tokens=842
14:10:36,566 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:36,570 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.204000000027008. input_tokens=2234, output_tokens=215
14:10:36,621 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:36,626 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.0619999999762513. input_tokens=2234, output_tokens=163
14:10:36,776 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:36,778 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.64100000000326. input_tokens=2232, output_tokens=364
14:10:37,74 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:37,79 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.829000000027008. input_tokens=2234, output_tokens=241
14:10:37,172 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:37,175 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.577999999979511. input_tokens=2233, output_tokens=354
14:10:37,282 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:37,285 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.9060000000172295. input_tokens=2234, output_tokens=143
14:10:37,434 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:37,437 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.1560000000172295. input_tokens=2234, output_tokens=205
14:10:38,65 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:38,68 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.51600000000326. input_tokens=2234, output_tokens=437
14:10:38,627 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:38,631 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 12.327999999979511. input_tokens=2234, output_tokens=383
14:10:38,730 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:38,733 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.0310000000172295. input_tokens=2234, output_tokens=301
14:10:38,805 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:38,808 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.6560000000172295. input_tokens=2234, output_tokens=392
14:10:38,947 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:38,951 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.10999999998603. input_tokens=2234, output_tokens=323
14:10:39,344 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:39,347 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.625. input_tokens=2233, output_tokens=343
14:10:39,854 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:39,858 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.563000000023749. input_tokens=2234, output_tokens=352
14:10:39,959 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:39,962 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.875. input_tokens=2234, output_tokens=336
14:10:40,510 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:40,514 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.375. input_tokens=2234, output_tokens=541
14:10:40,595 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:40,599 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.485000000044238. input_tokens=2234, output_tokens=376
14:10:41,18 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:41,24 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.7189999999827705. input_tokens=2233, output_tokens=365
14:10:41,313 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:41,316 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.75. input_tokens=2234, output_tokens=389
14:10:41,707 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:41,711 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.094000000040978. input_tokens=2234, output_tokens=379
14:10:42,186 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:42,191 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.10999999998603. input_tokens=2234, output_tokens=348
14:10:42,280 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:42,283 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.51500000001397. input_tokens=2233, output_tokens=421
14:10:42,531 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:42,540 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.9060000000172295. input_tokens=2234, output_tokens=548
14:10:42,756 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:42,760 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.327999999979511. input_tokens=2234, output_tokens=397
14:10:43,410 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:43,418 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.21799999999348. input_tokens=2233, output_tokens=620
14:10:43,446 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:43,455 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.39000000001397. input_tokens=2234, output_tokens=429
14:10:43,922 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:43,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.952999999979511. input_tokens=2234, output_tokens=546
14:10:44,119 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:44,122 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.59299999999348. input_tokens=2233, output_tokens=546
14:10:44,744 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:44,748 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.561999999976251. input_tokens=2234, output_tokens=456
14:10:44,769 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:44,774 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.14100000000326. input_tokens=2234, output_tokens=292
14:10:44,844 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:44,852 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.25. input_tokens=2234, output_tokens=575
14:10:45,119 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:45,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.764999999955762. input_tokens=2234, output_tokens=414
14:10:45,208 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:45,212 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.922000000020489. input_tokens=2234, output_tokens=514
14:10:45,231 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:45,239 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.952999999979511. input_tokens=2235, output_tokens=608
14:10:45,344 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:45,351 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.328000000037719. input_tokens=2233, output_tokens=322
14:10:45,555 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:45,559 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.60899999999674. input_tokens=2234, output_tokens=460
14:10:46,151 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:46,157 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.187999999965541. input_tokens=2234, output_tokens=457
14:10:46,174 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:46,177 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.85899999999674. input_tokens=2234, output_tokens=290
14:10:46,227 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:46,234 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:46,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.73399999999674. input_tokens=2234, output_tokens=334
14:10:46,241 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.514999999955762. input_tokens=2234, output_tokens=443
14:10:46,400 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:46,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.5939999999827705. input_tokens=2234, output_tokens=458
14:10:46,446 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:46,448 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.25. input_tokens=2234, output_tokens=328
14:10:47,368 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:47,372 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.764999999955762. input_tokens=2234, output_tokens=428
14:10:47,415 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:47,420 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.98399999999674. input_tokens=2233, output_tokens=424
14:10:47,689 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:47,693 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.8439999999827705. input_tokens=2233, output_tokens=607
14:10:48,11 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:48,15 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.8910000000032596. input_tokens=2234, output_tokens=249
14:10:48,222 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:48,223 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:48,227 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.688000000023749. input_tokens=2234, output_tokens=507
14:10:48,230 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.51600000000326. input_tokens=2234, output_tokens=487
14:10:48,348 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:48,351 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.938000000023749. input_tokens=2234, output_tokens=322
14:10:48,571 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:48,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.813000000023749. input_tokens=2234, output_tokens=379
14:10:48,850 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:48,853 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.563000000023749. input_tokens=2233, output_tokens=417
14:10:48,963 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:48,967 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.10899999999674. input_tokens=2235, output_tokens=268
14:10:49,467 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:49,470 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.719000000040978. input_tokens=2234, output_tokens=298
14:10:49,659 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:49,664 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.73399999999674. input_tokens=2234, output_tokens=394
14:10:49,878 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:49,883 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.4839999999967404. input_tokens=2234, output_tokens=203
14:10:49,954 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:49,957 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.7810000000172295. input_tokens=2233, output_tokens=255
14:10:50,124 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:50,133 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.921999999962281. input_tokens=2234, output_tokens=407
14:10:50,250 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:50,255 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.14100000000326. input_tokens=2233, output_tokens=395
14:10:50,805 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:50,807 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.452999999979511. input_tokens=2234, output_tokens=124
14:10:50,936 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:50,940 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.5. input_tokens=2234, output_tokens=271
14:10:50,996 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:51,0 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.436999999976251. input_tokens=2234, output_tokens=260
14:10:51,413 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:51,417 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.25. input_tokens=2234, output_tokens=366
14:10:51,470 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:51,473 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.625. input_tokens=2234, output_tokens=130
14:10:51,656 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:51,659 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.311999999976251. input_tokens=2234, output_tokens=142
14:10:51,744 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:51,749 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.375. input_tokens=2234, output_tokens=341
14:10:51,831 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:51,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.26500000001397. input_tokens=2234, output_tokens=241
14:10:51,852 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:51,856 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.844000000040978. input_tokens=2234, output_tokens=271
14:10:52,254 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:52,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.796999999962281. input_tokens=2235, output_tokens=474
14:10:52,750 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:52,757 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.51600000000326. input_tokens=2233, output_tokens=388
14:10:53,83 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:53,89 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.7810000000172295. input_tokens=2234, output_tokens=414
14:10:53,577 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:53,583 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.922000000020489. input_tokens=2233, output_tokens=333
14:10:53,686 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:53,696 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.73499999998603. input_tokens=2233, output_tokens=284
14:10:53,988 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:53,992 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.577999999979511. input_tokens=2234, output_tokens=583
14:10:54,45 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:54,48 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.0939999999827705. input_tokens=2234, output_tokens=310
14:10:54,77 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:54,81 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.39000000001397. input_tokens=2234, output_tokens=452
14:10:54,222 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:54,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.453000000037719. input_tokens=2234, output_tokens=411
14:10:54,980 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:54,988 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.73399999999674. input_tokens=2234, output_tokens=250
14:10:55,243 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:55,247 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.23399999999674. input_tokens=2233, output_tokens=364
14:10:55,352 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:55,355 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.469000000040978. input_tokens=2233, output_tokens=389
14:10:55,647 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:55,651 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.407000000006519. input_tokens=2234, output_tokens=270
14:10:56,250 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:56,253 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.452999999979511. input_tokens=2234, output_tokens=363
14:10:56,314 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:56,318 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.09399999998277. input_tokens=2234, output_tokens=418
14:10:56,435 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:56,441 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.952999999979511. input_tokens=2234, output_tokens=420
14:10:56,454 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:56,458 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.797000000020489. input_tokens=2233, output_tokens=339
14:10:56,571 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:56,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 11.329000000027008. input_tokens=2234, output_tokens=393
14:10:56,615 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:56,618 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.780999999959022. input_tokens=2234, output_tokens=483
14:10:56,792 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:56,795 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.0310000000172295. input_tokens=2234, output_tokens=403
14:10:56,809 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:56,812 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.672000000020489. input_tokens=2234, output_tokens=232
14:10:57,694 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:57,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.60999999998603. input_tokens=2234, output_tokens=251
14:10:57,980 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:57,983 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.0310000000172295. input_tokens=2234, output_tokens=675
14:10:58,135 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:58,139 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.905999999959022. input_tokens=2234, output_tokens=324
14:10:58,598 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:58,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.547000000020489. input_tokens=2234, output_tokens=353
14:10:58,704 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:58,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.3589999999967404. input_tokens=2234, output_tokens=213
14:10:58,721 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:58,725 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.875. input_tokens=2233, output_tokens=528
14:10:59,60 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:59,64 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.4060000000172295. input_tokens=2234, output_tokens=235
14:10:59,392 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:59,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.812999999965541. input_tokens=2234, output_tokens=295
14:10:59,475 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:59,478 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.235000000044238. input_tokens=2233, output_tokens=275
14:10:59,685 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:59,688 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.938000000023749. input_tokens=2235, output_tokens=337
14:10:59,705 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:59,710 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.453000000037719. input_tokens=2234, output_tokens=429
14:10:59,764 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:10:59,772 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.062999999965541. input_tokens=2231, output_tokens=270
14:11:00,40 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:00,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.625. input_tokens=2233, output_tokens=419
14:11:00,72 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:00,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.8130000000237487. input_tokens=2234, output_tokens=252
14:11:00,351 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:00,358 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.7810000000172295. input_tokens=2234, output_tokens=135
14:11:00,492 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:00,496 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.045999999972992. input_tokens=2234, output_tokens=285
14:11:00,515 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:00,519 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.3910000000032596. input_tokens=2234, output_tokens=127
14:11:00,533 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:00,540 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.547000000020489. input_tokens=2234, output_tokens=404
14:11:00,934 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:00,937 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.202999999979511. input_tokens=2234, output_tokens=135
14:11:01,92 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:01,98 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.7030000000377186. input_tokens=2233, output_tokens=87
14:11:01,542 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:01,545 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.717999999993481. input_tokens=2233, output_tokens=337
14:11:01,585 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:01,589 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.1089999999967404. input_tokens=2234, output_tokens=126
14:11:01,687 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:01,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 12.21899999998277. input_tokens=2234, output_tokens=314
14:11:01,755 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:01,759 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.061999999976251. input_tokens=2234, output_tokens=256
14:11:01,786 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:01,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.467999999993481. input_tokens=2233, output_tokens=293
14:11:01,968 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:01,973 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.9060000000172295. input_tokens=2233, output_tokens=135
14:11:02,61 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:02,65 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.077999999979511. input_tokens=2234, output_tokens=260
14:11:02,158 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:02,164 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.4679999999934807. input_tokens=2234, output_tokens=130
14:11:02,252 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:02,255 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.5469999999622814. input_tokens=2234, output_tokens=236
14:11:02,348 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:02,352 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.89100000000326. input_tokens=2234, output_tokens=316
14:11:03,153 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:03,158 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.35999999998603. input_tokens=2233, output_tokens=292
14:11:03,267 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:03,274 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.671999999962281. input_tokens=2234, output_tokens=347
14:11:03,509 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:03,515 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.89100000000326. input_tokens=2234, output_tokens=357
14:11:03,553 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:03,558 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.7810000000172295. input_tokens=2234, output_tokens=270
14:11:04,328 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:04,349 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.25. input_tokens=2232, output_tokens=314
14:11:04,512 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:04,520 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.4219999999622814. input_tokens=2088, output_tokens=219
14:11:04,885 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:04,897 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.90700000000652. input_tokens=2234, output_tokens=291
14:11:05,952 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:05,960 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.922000000020489. input_tokens=2234, output_tokens=340
14:11:06,134 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:06,141 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.186999999976251. input_tokens=2234, output_tokens=248
14:11:06,674 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:06,681 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.9689999999827705. input_tokens=2234, output_tokens=239
14:11:07,312 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:07,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.782000000006519. input_tokens=2234, output_tokens=307
14:11:07,387 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:07,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.032000000006519. input_tokens=2234, output_tokens=475
14:11:07,668 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:07,671 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.172000000020489. input_tokens=2234, output_tokens=368
14:11:08,699 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:08,713 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.187000000034459. input_tokens=2232, output_tokens=309
14:11:09,827 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:09,833 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 16.75. input_tokens=2234, output_tokens=310
14:11:09,878 datashaper.workflow.workflow INFO executing verb merge_graphs
14:11:10,303 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
14:11:10,613 graphrag.index.run INFO Running workflow: create_summarized_entities...
14:11:10,613 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
14:11:10,614 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
14:11:10,689 datashaper.workflow.workflow INFO executing verb summarize_descriptions
14:11:12,270 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:12,273 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2660000000032596. input_tokens=174, output_tokens=28
14:11:12,329 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:12,332 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1089999999967404. input_tokens=172, output_tokens=20
14:11:12,496 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:12,499 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.375. input_tokens=168, output_tokens=41
14:11:12,663 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:12,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6400000000139698. input_tokens=189, output_tokens=46
14:11:12,957 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:12,989 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9209999999729916. input_tokens=216, output_tokens=73
14:11:14,111 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,117 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8589999999967404. input_tokens=176, output_tokens=33
14:11:14,158 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,165 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5. input_tokens=197, output_tokens=37
14:11:14,228 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,232 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.875. input_tokens=169, output_tokens=34
14:11:14,358 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,362 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.375. input_tokens=168, output_tokens=36
14:11:14,461 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,465 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1560000000172295. input_tokens=199, output_tokens=78
14:11:14,585 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,591 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.26500000001397. input_tokens=219, output_tokens=50
14:11:14,677 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,680 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.452999999979511. input_tokens=209, output_tokens=55
14:11:14,753 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,755 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.4839999999967404. input_tokens=201, output_tokens=57
14:11:14,801 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,803 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.4380000000237487. input_tokens=336, output_tokens=82
14:11:14,826 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:14,831 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.7810000000172295. input_tokens=364, output_tokens=134
14:11:15,33 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,36 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.875. input_tokens=242, output_tokens=58
14:11:15,183 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,187 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8439999999827705. input_tokens=294, output_tokens=121
14:11:15,262 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,265 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.125. input_tokens=181, output_tokens=40
14:11:15,306 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,311 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.0939999999827705. input_tokens=303, output_tokens=138
14:11:15,366 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.217999999993481. input_tokens=313, output_tokens=122
14:11:15,385 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,389 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.030999999959022. input_tokens=249, output_tokens=108
14:11:15,390 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.296999999962281. input_tokens=278, output_tokens=106
14:11:15,450 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,454 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0940000000409782. input_tokens=171, output_tokens=23
14:11:15,475 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,481 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3600000000442378. input_tokens=226, output_tokens=59
14:11:15,584 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,587 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.344000000040978. input_tokens=258, output_tokens=96
14:11:15,662 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,664 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.077999999979511. input_tokens=171, output_tokens=22
14:11:15,798 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,802 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.047000000020489. input_tokens=192, output_tokens=30
14:11:15,823 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,826 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.48499999998603. input_tokens=164, output_tokens=19
14:11:15,925 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:15,928 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.4380000000237487. input_tokens=177, output_tokens=44
14:11:16,460 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,463 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6560000000172295. input_tokens=244, output_tokens=78
14:11:16,577 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,583 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2810000000172295. input_tokens=185, output_tokens=48
14:11:16,623 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,632 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1410000000032596. input_tokens=173, output_tokens=40
14:11:16,670 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,674 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.672000000020489. input_tokens=422, output_tokens=161
14:11:16,720 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,721 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,727 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5630000000237487. input_tokens=286, output_tokens=122
14:11:16,732 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.297000000020489. input_tokens=182, output_tokens=48
14:11:16,782 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,789 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.75. input_tokens=227, output_tokens=91
14:11:16,862 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,867 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.827999999979511. input_tokens=456, output_tokens=157
14:11:16,879 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2969999999622814. input_tokens=165, output_tokens=37
14:11:16,905 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:16,910 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5150000000139698. input_tokens=181, output_tokens=44
14:11:17,181 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,186 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5160000000032596. input_tokens=178, output_tokens=41
14:11:17,220 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,225 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7660000000032596. input_tokens=186, output_tokens=42
14:11:17,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.780999999959022. input_tokens=386, output_tokens=176
14:11:17,297 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,301 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4839999999967404. input_tokens=197, output_tokens=88
14:11:17,368 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,372 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.530999999959022. input_tokens=352, output_tokens=134
14:11:17,374 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,390 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1410000000032596. input_tokens=515, output_tokens=238
14:11:17,411 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,415 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6089999999967404. input_tokens=199, output_tokens=73
14:11:17,495 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,498 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.125. input_tokens=231, output_tokens=83
14:11:17,718 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,722 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.422000000020489. input_tokens=612, output_tokens=225
14:11:17,926 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:17,930 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.8439999999827705. input_tokens=650, output_tokens=368
14:11:18,120 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2809999999590218. input_tokens=171, output_tokens=34
14:11:18,135 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,138 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4059999999590218. input_tokens=186, output_tokens=47
14:11:18,162 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,171 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5310000000172295. input_tokens=188, output_tokens=47
14:11:18,250 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,252 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3119999999762513. input_tokens=182, output_tokens=42
14:11:18,269 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,272 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.5939999999827705. input_tokens=175, output_tokens=23
14:11:18,345 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,350 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4530000000377186. input_tokens=171, output_tokens=62
14:11:18,463 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,468 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1560000000172295. input_tokens=163, output_tokens=37
14:11:18,544 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,546 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1560000000172295. input_tokens=159, output_tokens=27
14:11:18,601 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8600000000442378. input_tokens=183, output_tokens=56
14:11:18,653 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,655 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,657 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,660 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4839999999967404. input_tokens=208, output_tokens=59
14:11:18,665 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.172000000020489. input_tokens=174, output_tokens=33
14:11:18,670 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2179999999934807. input_tokens=169, output_tokens=33
14:11:18,717 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,725 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.547000000020489. input_tokens=739, output_tokens=264
14:11:18,917 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,919 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9839999999967404. input_tokens=375, output_tokens=161
14:11:18,981 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:18,983 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3910000000032596. input_tokens=287, output_tokens=127
14:11:19,187 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,192 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9540000000270084. input_tokens=219, output_tokens=89
14:11:19,219 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,226 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5. input_tokens=183, output_tokens=49
14:11:19,336 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,338 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0780000000377186. input_tokens=154, output_tokens=29
14:11:19,397 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,400 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,406 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.14100000000326. input_tokens=565, output_tokens=261
14:11:19,410 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5310000000172295. input_tokens=306, output_tokens=178
14:11:19,450 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,454 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.25. input_tokens=166, output_tokens=39
14:11:19,520 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,543 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4070000000065193. input_tokens=177, output_tokens=44
14:11:19,587 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4839999999967404. input_tokens=167, output_tokens=42
14:11:19,664 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,667 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0619999999762513. input_tokens=185, output_tokens=28
14:11:19,751 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,755 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2189999999827705. input_tokens=171, output_tokens=26
14:11:19,881 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,884 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.952999999979511. input_tokens=268, output_tokens=116
14:11:19,941 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,945 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:19,948 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4849999999860302. input_tokens=198, output_tokens=67
14:11:19,952 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.23499999998603. input_tokens=752, output_tokens=200
14:11:20,130 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,134 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.452999999979511. input_tokens=176, output_tokens=47
14:11:20,195 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,198 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9380000000237487. input_tokens=188, output_tokens=60
14:11:20,212 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,214 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,216 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.875. input_tokens=150, output_tokens=24
14:11:20,219 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4839999999967404. input_tokens=177, output_tokens=52
14:11:20,400 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,406 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.125. input_tokens=234, output_tokens=100
14:11:20,503 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,506 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5939999999827705. input_tokens=180, output_tokens=56
14:11:20,638 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,640 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,642 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,645 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6719999999622814. input_tokens=206, output_tokens=68
14:11:20,648 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,650 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2189999999827705. input_tokens=187, output_tokens=32
14:11:20,653 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4219999999622814. input_tokens=168, output_tokens=40
14:11:20,669 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4679999999934807. input_tokens=173, output_tokens=43
14:11:20,709 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:20,714 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.297000000020489. input_tokens=160, output_tokens=30
14:11:21,31 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,39 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.375. input_tokens=227, output_tokens=114
14:11:21,117 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,119 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.7339999999967404. input_tokens=168, output_tokens=47
14:11:21,185 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,209 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.75. input_tokens=1161, output_tokens=337
14:11:21,233 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,236 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7809999999590218. input_tokens=195, output_tokens=95
14:11:21,255 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,260 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5939999999827705. input_tokens=189, output_tokens=54
14:11:21,326 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,333 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9839999999967404. input_tokens=174, output_tokens=41
14:11:21,380 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,384 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1869999999762513. input_tokens=180, output_tokens=38
14:11:21,396 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,401 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1719999999622814. input_tokens=184, output_tokens=54
14:11:21,450 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,451 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,453 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8290000000270084. input_tokens=223, output_tokens=90
14:11:21,455 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9060000000172295. input_tokens=200, output_tokens=70
14:11:21,482 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,487 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3589999999967404. input_tokens=189, output_tokens=42
14:11:21,726 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,729 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7810000000172295. input_tokens=336, output_tokens=96
14:11:21,767 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,770 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0939999999827705. input_tokens=163, output_tokens=19
14:11:21,838 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.437000000034459. input_tokens=174, output_tokens=47
14:11:21,882 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,884 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.375. input_tokens=179, output_tokens=51
14:11:21,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2189999999827705. input_tokens=162, output_tokens=18
14:11:21,990 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:21,993 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2959999999729916. input_tokens=162, output_tokens=26
14:11:22,54 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,56 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4060000000172295. input_tokens=165, output_tokens=34
14:11:22,249 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,253 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.98399999999674. input_tokens=4178, output_tokens=503
14:11:22,591 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,595 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3440000000409782. input_tokens=180, output_tokens=28
14:11:22,647 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,651 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7660000000032596. input_tokens=325, output_tokens=153
14:11:22,694 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,696 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.0. input_tokens=422, output_tokens=210
14:11:22,776 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,781 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3910000000032596. input_tokens=172, output_tokens=37
14:11:22,813 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,816 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5939999999827705. input_tokens=311, output_tokens=135
14:11:22,897 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,901 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4070000000065193. input_tokens=169, output_tokens=38
14:11:22,922 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,927 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8130000000237487. input_tokens=206, output_tokens=62
14:11:22,945 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:22,949 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0630000000237487. input_tokens=177, output_tokens=33
14:11:23,1 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,7 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6719999999622814. input_tokens=184, output_tokens=59
14:11:23,57 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,59 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2189999999827705. input_tokens=174, output_tokens=42
14:11:23,117 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,120 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3899999999557622. input_tokens=179, output_tokens=39
14:11:23,189 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,193 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9540000000270084. input_tokens=185, output_tokens=61
14:11:23,261 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,266 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3589999999967404. input_tokens=167, output_tokens=40
14:11:23,281 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,283 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,287 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.077999999979511. input_tokens=275, output_tokens=96
14:11:23,290 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.827999999979511. input_tokens=182, output_tokens=51
14:11:23,351 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,358 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.297000000020489. input_tokens=178, output_tokens=50
14:11:23,502 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0469999999622814. input_tokens=176, output_tokens=55
14:11:23,720 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,725 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8280000000377186. input_tokens=176, output_tokens=23
14:11:23,881 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0619999999762513. input_tokens=171, output_tokens=23
14:11:23,909 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:23,915 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.922000000020489. input_tokens=229, output_tokens=86
14:11:24,100 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,104 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4530000000377186. input_tokens=202, output_tokens=31
14:11:24,108 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,134 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.4219999999622814. input_tokens=323, output_tokens=125
14:11:24,222 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,225 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,227 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5459999999729916. input_tokens=168, output_tokens=33
14:11:24,242 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2959999999729916. input_tokens=200, output_tokens=44
14:11:24,251 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3119999999762513. input_tokens=192, output_tokens=41
14:11:24,256 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,320 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,325 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5320000000065193. input_tokens=182, output_tokens=45
14:11:24,334 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.562000000034459. input_tokens=189, output_tokens=46
14:11:24,356 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,357 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,362 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.25. input_tokens=202, output_tokens=44
14:11:24,365 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.327999999979511. input_tokens=299, output_tokens=132
14:11:24,389 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.6560000000172295. input_tokens=682, output_tokens=305
14:11:24,449 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,452 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,465 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.062000000034459. input_tokens=217, output_tokens=88
14:11:24,468 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0940000000409782. input_tokens=172, output_tokens=33
14:11:24,541 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,551 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3589999999967404. input_tokens=179, output_tokens=38
14:11:24,581 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5310000000172295. input_tokens=174, output_tokens=41
14:11:24,743 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,746 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4369999999762513. input_tokens=170, output_tokens=37
14:11:24,887 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:24,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6089999999967404. input_tokens=176, output_tokens=46
14:11:25,35 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,38 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7810000000172295. input_tokens=452, output_tokens=162
14:11:25,87 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,89 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0780000000377186. input_tokens=238, output_tokens=82
14:11:25,125 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,132 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.171999999962281. input_tokens=483, output_tokens=287
14:11:25,372 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,380 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4689999999827705. input_tokens=198, output_tokens=39
14:11:25,411 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,416 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,419 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6869999999762513. input_tokens=230, output_tokens=76
14:11:25,425 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.827999999979511. input_tokens=415, output_tokens=140
14:11:25,488 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,493 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6089999999967404. input_tokens=230, output_tokens=82
14:11:25,568 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,571 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0630000000237487. input_tokens=334, output_tokens=146
14:11:25,592 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,594 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,597 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3440000000409782. input_tokens=166, output_tokens=34
14:11:25,599 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4690000000409782. input_tokens=173, output_tokens=16
14:11:25,628 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,632 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3439999999827705. input_tokens=270, output_tokens=101
14:11:25,670 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,676 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.297000000020489. input_tokens=169, output_tokens=15
14:11:25,677 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,692 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3599999999860302. input_tokens=171, output_tokens=43
14:11:25,714 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,721 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6100000000442378. input_tokens=206, output_tokens=56
14:11:25,742 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,749 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.375. input_tokens=169, output_tokens=30
14:11:25,821 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:25,826 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5320000000065193. input_tokens=179, output_tokens=41
14:11:26,31 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1560000000172295. input_tokens=183, output_tokens=47
14:11:26,85 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,95 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4690000000409782. input_tokens=192, output_tokens=46
14:11:26,123 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,128 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0939999999827705. input_tokens=169, output_tokens=31
14:11:26,148 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,154 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7189999999827705. input_tokens=272, output_tokens=86
14:11:26,227 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,230 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8910000000032596. input_tokens=221, output_tokens=74
14:11:26,332 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,334 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,337 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2030000000377186. input_tokens=162, output_tokens=20
14:11:26,341 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.25. input_tokens=181, output_tokens=41
14:11:26,427 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,429 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.922000000020489. input_tokens=209, output_tokens=115
14:11:26,523 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,525 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0469999999622814. input_tokens=218, output_tokens=71
14:11:26,727 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,730 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.172000000020489. input_tokens=242, output_tokens=90
14:11:26,745 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,748 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3589999999967404. input_tokens=255, output_tokens=72
14:11:26,806 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,808 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.375. input_tokens=182, output_tokens=32
14:11:26,937 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:26,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2040000000270084. input_tokens=222, output_tokens=75
14:11:27,177 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,179 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4839999999967404. input_tokens=188, output_tokens=47
14:11:27,329 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,332 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.297000000020489. input_tokens=173, output_tokens=31
14:11:27,347 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,349 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,352 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5780000000377186. input_tokens=183, output_tokens=49
14:11:27,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.75. input_tokens=247, output_tokens=103
14:11:27,456 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,460 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8440000000409782. input_tokens=224, output_tokens=104
14:11:27,516 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,519 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.952999999979511. input_tokens=205, output_tokens=83
14:11:27,664 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,668 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8429999999934807. input_tokens=175, output_tokens=36
14:11:27,760 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.077999999979511. input_tokens=303, output_tokens=120
14:11:27,772 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,775 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6719999999622814. input_tokens=185, output_tokens=74
14:11:27,825 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:27,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4689999999827705. input_tokens=183, output_tokens=50
14:11:28,50 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,53 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1089999999967404. input_tokens=173, output_tokens=40
14:11:28,92 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,93 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,94 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,96 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5780000000377186. input_tokens=180, output_tokens=66
14:11:28,97 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.375. input_tokens=172, output_tokens=39
14:11:28,100 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.375. input_tokens=242, output_tokens=103
14:11:28,452 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,456 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.10999999998603. input_tokens=278, output_tokens=126
14:11:28,522 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,525 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3439999999827705. input_tokens=166, output_tokens=33
14:11:28,776 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,779 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6410000000032596. input_tokens=232, output_tokens=118
14:11:28,796 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,800 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4380000000237487. input_tokens=175, output_tokens=36
14:11:28,819 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,823 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3290000000270084. input_tokens=330, output_tokens=174
14:11:28,869 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:28,873 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0619999999762513. input_tokens=231, output_tokens=77
14:11:29,3 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,7 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2339999999967404. input_tokens=177, output_tokens=45
14:11:29,9 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,23 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3599999999860302. input_tokens=187, output_tokens=52
14:11:29,118 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,121 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9209999999729916. input_tokens=355, output_tokens=138
14:11:29,137 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2969999999622814. input_tokens=175, output_tokens=27
14:11:29,247 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.8119999999762513. input_tokens=430, output_tokens=185
14:11:29,313 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2660000000032596. input_tokens=171, output_tokens=28
14:11:29,317 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,330 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2190000000409782. input_tokens=171, output_tokens=65
14:11:29,333 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,347 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8280000000377186. input_tokens=188, output_tokens=57
14:11:29,399 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.875. input_tokens=166, output_tokens=17
14:11:29,456 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,458 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.8280000000377186. input_tokens=559, output_tokens=253
14:11:29,561 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,565 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8290000000270084. input_tokens=237, output_tokens=131
14:11:29,626 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,630 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5309999999590218. input_tokens=186, output_tokens=54
14:11:29,655 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,659 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5619999999762513. input_tokens=175, output_tokens=43
14:11:29,726 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:29,730 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9530000000377186. input_tokens=163, output_tokens=15
14:11:30,80 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,83 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,87 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2650000000139698. input_tokens=170, output_tokens=36
14:11:30,90 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2810000000172295. input_tokens=166, output_tokens=34
14:11:30,151 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,154 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3910000000032596. input_tokens=287, output_tokens=98
14:11:30,249 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3589999999967404. input_tokens=168, output_tokens=39
14:11:30,283 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,291 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.952999999979511. input_tokens=230, output_tokens=126
14:11:30,394 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,400 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3910000000032596. input_tokens=180, output_tokens=57
14:11:30,525 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,527 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,529 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.375. input_tokens=184, output_tokens=47
14:11:30,532 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.062999999965541. input_tokens=183, output_tokens=39
14:11:30,598 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,601 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.172000000020489. input_tokens=664, output_tokens=333
14:11:30,661 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,665 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.327999999979511. input_tokens=179, output_tokens=52
14:11:30,690 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,696 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3439999999827705. input_tokens=360, output_tokens=184
14:11:30,788 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,792 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,796 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4369999999762513. input_tokens=187, output_tokens=58
14:11:30,801 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4060000000172295. input_tokens=167, output_tokens=33
14:11:30,911 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,915 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,919 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:30,923 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.452999999979511. input_tokens=190, output_tokens=57
14:11:30,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.702999999979511. input_tokens=987, output_tokens=333
14:11:30,935 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3589999999967404. input_tokens=179, output_tokens=45
14:11:31,124 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,129 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5. input_tokens=188, output_tokens=41
14:11:31,199 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,203 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.73499999998603. input_tokens=300, output_tokens=153
14:11:31,288 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,291 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.172000000020489. input_tokens=215, output_tokens=123
14:11:31,334 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,336 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2339999999967404. input_tokens=177, output_tokens=38
14:11:31,454 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,461 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.797000000020489. input_tokens=227, output_tokens=58
14:11:31,465 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,475 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3910000000032596. input_tokens=192, output_tokens=60
14:11:31,482 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,493 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.202999999979511. input_tokens=176, output_tokens=40
14:11:31,581 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,584 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,591 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.26500000001397. input_tokens=180, output_tokens=46
14:11:31,597 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0630000000237487. input_tokens=159, output_tokens=14
14:11:31,620 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,625 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4679999999934807. input_tokens=197, output_tokens=56
14:11:31,670 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,675 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6560000000172295. input_tokens=318, output_tokens=157
14:11:31,783 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,793 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5310000000172295. input_tokens=170, output_tokens=40
14:11:31,863 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,870 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2649999999557622. input_tokens=164, output_tokens=28
14:11:31,875 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,885 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2189999999827705. input_tokens=162, output_tokens=27
14:11:31,978 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:31,988 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5929999999934807. input_tokens=197, output_tokens=51
14:11:32,18 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:32,32 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.202999999979511. input_tokens=208, output_tokens=47
14:11:32,110 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:32,114 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1869999999762513. input_tokens=175, output_tokens=31
14:11:32,222 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:32,229 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5310000000172295. input_tokens=201, output_tokens=57
14:11:32,295 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:32,304 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.577999999979511. input_tokens=276, output_tokens=138
14:11:32,460 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:32,470 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.922000000020489. input_tokens=212, output_tokens=87
14:11:32,666 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:32,674 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.375. input_tokens=1020, output_tokens=506
14:11:33,91 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:33,100 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.860000000044238. input_tokens=188, output_tokens=34
14:11:33,533 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:33,538 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7339999999967404. input_tokens=277, output_tokens=89
14:11:34,232 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:34,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.280999999959022. input_tokens=186, output_tokens=51
14:11:34,378 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
14:11:34,636 graphrag.index.run INFO Running workflow: create_base_entity_graph...
14:11:34,636 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
14:11:34,637 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
14:11:34,694 datashaper.workflow.workflow INFO executing verb cluster_graph
14:11:35,381 datashaper.workflow.workflow INFO executing verb select
14:11:35,397 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
14:11:35,745 graphrag.index.run INFO Running workflow: create_final_entities...
14:11:35,745 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
14:11:35,747 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
14:11:35,817 datashaper.workflow.workflow INFO executing verb unpack_graph
14:11:36,55 datashaper.workflow.workflow INFO executing verb rename
14:11:36,94 datashaper.workflow.workflow INFO executing verb select
14:11:36,127 datashaper.workflow.workflow INFO executing verb dedupe
14:11:36,156 datashaper.workflow.workflow INFO executing verb rename
14:11:36,183 datashaper.workflow.workflow INFO executing verb filter
14:11:36,271 datashaper.workflow.workflow INFO executing verb text_split
14:11:36,337 datashaper.workflow.workflow INFO executing verb drop
14:11:36,398 datashaper.workflow.workflow INFO executing verb merge
14:11:36,740 datashaper.workflow.workflow INFO executing verb text_embed
14:11:36,746 graphrag.llm.openai.create_openai_client INFO Creating Azure OpenAI client api_base=https://cognisearch.openai.azure.com, deployment_name=text-embedding-3-small
14:11:37,442 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
14:11:37,442 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
14:11:37,526 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 368 inputs via 368 snippets using 23 batches. max_batch_size=16, max_tokens=8191
14:11:39,339 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,548 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,554 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,560 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,570 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,591 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,613 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,636 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,681 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,706 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,746 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,770 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,775 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,808 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,848 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,863 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,867 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,869 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,884 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,947 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:39,973 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:40,118 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:40,223 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:11:40,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.125. input_tokens=655, output_tokens=0
14:11:40,758 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.155999999959022. input_tokens=588, output_tokens=0
14:11:40,801 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.202999999979511. input_tokens=679, output_tokens=0
14:11:40,915 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.2810000000172295. input_tokens=699, output_tokens=0
14:11:41,31 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.452999999979511. input_tokens=582, output_tokens=0
14:11:41,104 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.485000000044238. input_tokens=576, output_tokens=0
14:11:41,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.655999999959022. input_tokens=858, output_tokens=0
14:11:41,324 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.7189999999827705. input_tokens=532, output_tokens=0
14:11:41,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.7660000000032596. input_tokens=586, output_tokens=0
14:11:41,451 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.8910000000032596. input_tokens=1097, output_tokens=0
14:11:41,504 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.9369999999762513. input_tokens=1111, output_tokens=0
14:11:41,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.9689999999827705. input_tokens=600, output_tokens=0
14:11:41,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.1560000000172295. input_tokens=661, output_tokens=0
14:11:41,776 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.2189999999827705. input_tokens=1100, output_tokens=0
14:11:41,900 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.327999999979511. input_tokens=780, output_tokens=0
14:11:41,971 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.39100000000326. input_tokens=683, output_tokens=0
14:11:42,88 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.5. input_tokens=671, output_tokens=0
14:11:42,222 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.64100000000326. input_tokens=912, output_tokens=0
14:11:42,300 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.688000000023749. input_tokens=1448, output_tokens=0
14:11:42,361 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.795999999972992. input_tokens=1645, output_tokens=0
14:11:42,421 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.797000000020489. input_tokens=770, output_tokens=0
14:11:42,545 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.0. input_tokens=1524, output_tokens=0
14:11:42,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.01600000000326. input_tokens=582, output_tokens=0
14:11:42,902 datashaper.workflow.workflow INFO executing verb drop
14:11:42,934 datashaper.workflow.workflow INFO executing verb filter
14:11:42,983 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
14:11:43,581 graphrag.index.run INFO Running workflow: create_final_nodes...
14:11:43,582 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
14:11:43,584 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
14:11:43,658 datashaper.workflow.workflow INFO executing verb layout_graph
14:11:45,50 datashaper.workflow.workflow INFO executing verb unpack_graph
14:11:45,437 datashaper.workflow.workflow INFO executing verb unpack_graph
14:11:45,812 datashaper.workflow.workflow INFO executing verb filter
14:11:45,971 datashaper.workflow.workflow INFO executing verb drop
14:11:46,6 datashaper.workflow.workflow INFO executing verb select
14:11:46,47 datashaper.workflow.workflow INFO executing verb rename
14:11:46,147 datashaper.workflow.workflow INFO executing verb join
14:11:46,232 datashaper.workflow.workflow INFO executing verb convert
14:11:46,433 datashaper.workflow.workflow INFO executing verb rename
14:11:46,440 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
14:11:46,758 graphrag.index.run INFO Running workflow: create_final_communities...
14:11:46,759 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
14:11:46,760 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
14:11:46,846 datashaper.workflow.workflow INFO executing verb unpack_graph
14:11:47,217 datashaper.workflow.workflow INFO executing verb unpack_graph
14:11:47,554 datashaper.workflow.workflow INFO executing verb aggregate_override
14:11:47,610 datashaper.workflow.workflow INFO executing verb join
14:11:47,689 datashaper.workflow.workflow INFO executing verb join
14:11:47,770 datashaper.workflow.workflow INFO executing verb concat
14:11:47,826 datashaper.workflow.workflow INFO executing verb filter
14:11:48,954 datashaper.workflow.workflow INFO executing verb aggregate_override
14:11:49,51 datashaper.workflow.workflow INFO executing verb join
14:11:49,110 datashaper.workflow.workflow INFO executing verb filter
14:11:49,274 datashaper.workflow.workflow INFO executing verb fill
14:11:49,324 datashaper.workflow.workflow INFO executing verb merge
14:11:49,540 datashaper.workflow.workflow INFO executing verb copy
14:11:49,603 datashaper.workflow.workflow INFO executing verb select
14:11:49,609 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
14:11:49,968 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
14:11:49,968 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
14:11:49,970 graphrag.index.run INFO read table from storage: create_final_entities.parquet
14:11:50,136 datashaper.workflow.workflow INFO executing verb select
14:11:50,204 datashaper.workflow.workflow INFO executing verb unroll
14:11:50,268 datashaper.workflow.workflow INFO executing verb aggregate_override
14:11:50,308 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
14:11:50,764 graphrag.index.run INFO Running workflow: create_final_relationships...
14:11:50,764 graphrag.index.run INFO dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
14:11:50,766 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
14:11:50,787 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
14:11:50,883 datashaper.workflow.workflow INFO executing verb unpack_graph
14:11:51,349 datashaper.workflow.workflow INFO executing verb filter
14:11:51,609 datashaper.workflow.workflow INFO executing verb rename
14:11:51,670 datashaper.workflow.workflow INFO executing verb filter
14:11:52,215 datashaper.workflow.workflow INFO executing verb drop
14:11:52,291 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
14:11:52,378 datashaper.workflow.workflow INFO executing verb convert
14:11:52,593 datashaper.workflow.workflow INFO executing verb convert
14:11:52,605 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
14:11:52,977 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
14:11:52,993 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
14:11:53,19 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
14:11:53,291 datashaper.workflow.workflow INFO executing verb select
14:11:53,373 datashaper.workflow.workflow INFO executing verb unroll
14:11:53,455 datashaper.workflow.workflow INFO executing verb aggregate_override
14:11:53,643 datashaper.workflow.workflow INFO executing verb select
14:11:53,652 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
14:11:54,26 graphrag.index.run INFO Running workflow: create_final_community_reports...
14:11:54,35 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
14:11:54,74 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
14:11:54,90 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
14:11:54,290 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
14:11:54,520 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
14:11:54,969 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
14:11:55,90 datashaper.workflow.workflow INFO executing verb prepare_community_reports
14:11:55,247 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 368
14:11:55,575 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 368
14:11:56,142 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 368
14:11:56,735 datashaper.workflow.workflow INFO executing verb create_community_reports
14:12:06,197 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:06,201 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.34399999998277. input_tokens=2236, output_tokens=610
14:12:07,594 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:07,597 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.688000000023749. input_tokens=2233, output_tokens=660
14:12:08,404 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:08,411 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.547000000020489. input_tokens=2333, output_tokens=705
14:12:10,315 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:10,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.35999999998603. input_tokens=2995, output_tokens=802
14:12:10,831 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:10,837 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.03100000001723. input_tokens=3699, output_tokens=1014
14:12:11,843 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:11,921 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.03100000001723. input_tokens=2532, output_tokens=700
14:12:12,704 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:12,713 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.78100000001723. input_tokens=2298, output_tokens=598
14:12:14,414 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:14,424 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 17.51500000001397. input_tokens=3125, output_tokens=1047
14:12:14,584 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:14,589 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 17.67200000002049. input_tokens=4299, output_tokens=1013
14:12:18,879 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:18,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 22.06199999997625. input_tokens=4033, output_tokens=1240
14:12:19,775 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:19,782 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 22.93799999996554. input_tokens=3209, output_tokens=858
14:12:32,629 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:32,638 graphrag.llm.openai.utils ERROR error loading json, json={
    "title": "Ebenezer Scrooge and His Transformative Journey",
    "summary": "The community revolves around Ebenezer Scrooge, a central character who undergoes a profound transformation from a miserly, solitary old man to a compassionate and generous individual. Key entities in this community include Jacob Marley, the Ghosts of Christmas Past, Present, and Yet to Come, and the Cratchit family. The relationships between these entities and Scrooge are pivotal in driving his transformation, with significant events occurring during the Christmas season.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the profound transformation of Scrooge and its significant influence on his community and relationships.",
    "findings": [
        {
            "summary": "Scrooge's initial demeanor and lifestyle",
            "explanation": "Ebenezer Scrooge is initially depicted as a tight-fisted, covetous, and solitary old man with a cold demeanor that affects his physical appearance. He is known for his bitter and unkind nature, indifferent to others, and enjoying isolation from human sympathy. Scrooge lives alone in a gloomy suite of rooms that once belonged to his deceased partner, Marley, and is familiar with the dark yard and the large knocker on the door. His skepticism and dismissive attitude towards Christmas, charitable activities, and his strained relationship with his nephew, Fred, further highlight his negative disposition [Data: Entities (29); Relationships (24, 124, 122, 51, 106, 109, 88, 205, 120, 210, 51, 106, 222, 59, 105, 108, 184, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245, 159, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245)]."
        },
        {
            "summary": "Jacob Marley's role in Scrooge's transformation",
            "explanation": "Jacob Marley, Scrooge's former business partner, plays a significant role in initiating Scrooge's transformation. As a ghost, Marley appears to Scrooge, explaining the chains he bears as a result of his greedy and selfish actions during his lifetime. Marley's ghostly presence is a significant supernatural event, as he enters through a door in Scrooge's home to deliver an important message. Marley's intervention includes sending a messenger to Scrooge and making predictions that influence Scrooge's actions and experiences [Data: Entities (105, 109); Relationships (158, 106, 156, 320, 323, 44, 321, 337)]."
        },
        {
            "summary": "The influence of the Ghosts of Christmas Past, Present, and Yet to Come",
            "explanation": "Scrooge is visited by several spirits, including the Ghost of Christmas Past, the Ghost of Christmas Present, and the Ghost of Christmas Yet to Come. These supernatural encounters lead him to reflect on his past actions, their impact on his life and others, and his potential future. The Ghost of Christmas Past shows Scrooge scenes from his past, causing him to reflect on his life. The Ghost of Christmas Present guides Scrooge during a crucial visit, highlighting the importance of charity and benevolence. The Ghost of Christmas Yet to Come shows Scrooge future events, causing him fear and solemn dread, ultimately leading to his desire for redemption and a reconsideration of his life choices [Data: Entities (283, 325); Relationships (172, 198, 203, 122, 206, 205, 120, 210, 51, 106, 222, 59, 105, 108, 184, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245, 159, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245)]."
        },
        {
            "summary": "Scrooge's transformation and newfound generosity",
            "explanation": "Scrooge's transformation is marked by his growing willingness to learn from the spirits and his increasing engagement with others. He becomes more reflective, showing pity for his former self and regret for not giving something to a boy singing a Christmas carol. He expresses a desire for Tiny Tim to be spared and shows an interest in the well-being of the Cratchit family. Scrooge's newfound generosity is evident in his actions, such as raising Bob Cratchit's salary and offering assistance, demonstrating his change in character [Data: Entities (342); Relationships (24, 204, 203, 205, 206, 51, 106, 222, 59, 105, 108, 184, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245, 159, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245)]."
        },
        {
            "summary": "The Cratchit family's significance in Scrooge's journey",
            "explanation": "The Cratchit family, particularly Bob Cratchit and Tiny Tim, play a significant role in Scrooge's transformation. Bob Cratchit is initially an employee who is eager to catch Scrooge coming late to the office and reluctant to give him a day off on Christmas Eve. Despite Scrooge's negative influence, Bob Cratchit tries to focus on positive prospects and enjoys Christmas Eve. Scrooge's growing concern and care for Tiny Tim signify a profound change in his character, as he becomes a second father to Tiny Tim and shows a significant interest in his well-being [Data: Entities (342); Relationships (24, 204, 203, 205, 206, 51, 106, 222, 59, 105, 108, 184, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245, 159, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245)]."
        },
        {
            "summary": "Scrooge's relationship with his nephew, Fred",
            "explanation": "Scrooge and his nephew share a complex familial relationship characterized by both tension and moments of connection. Despite their contrasting views on Christmas, with Scrooge holding a negative attitude and his nephew advocating for its goodness, they engage in meaningful dialogues where the nephew challenges Scrooge's perspective. Scrooge's nephew consistently tries to engage Scrooge in Christmas celebrations and social activities, greeting him cheerfully and inviting him to dine together, despite Scrooge's stern demeanor and dismissive attitude. This persistence highlights the nephew's good nature and desire to reconcile their strained relationship [Data: Relationships (122, 51, 106, 222, 59, 105, 108, 184, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245, 159, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245)]."
        },
        {
            "summary": "Scrooge's reflections on his past and its impact on his transformation",
            "explanation": "Throughout the story, Scrooge is guided by the spirits to witness various scenes, including his younger self in a melancholy room, the Cratchit family, and his own lonely death. He is deeply troubled by the appearance of Marley's Ghost and is determined to stay awake to witness the ghostly visitation. Scrooge's transformation is marked by his growing willingness to learn from the spirits and his increasing engagement with others. He becomes more reflective, showing pity for his former self and regret for not giving something to a boy singing a Christmas carol. He expresses a desire for Tiny Tim to be spared and shows an interest in the well-being of the Cratchit family [Data: Entities (342); Relationships (24, 204, 203, 205, 206, 51, 106, 222, 59, 105, 108, 184, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245, 159, 215, 223, 156, 119, 129, 139, 190, 193, 201, 212, 240, 245)]."
        },
        {
            "summary": "The role of supernatural entities in Scrooge's journey",
            "explanation": "Supernatural entities play a crucial role in Scrooge's journey towards transformation. The Ghost of Christmas Past, the Ghost of Christmas
Traceback (most recent call last):
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\openai\utils.py", line 93, in try_parse_json_object
    result = json.loads(input)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Unterminated string starting at: line 37 column 28 (char 7498)
14:12:32,649 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\index\graph\extractors\community_reports\community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\base\caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\base\base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 82, in _invoke_json
    result = await generate()
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 74, in generate
    await self._native_json(input, **{**kwargs, "name": call_name})
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 108, in _native_json
    json_output = try_parse_json_object(raw_output)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\site-packages\graphrag\llm\openai\utils.py", line 93, in try_parse_json_object
    result = json.loads(input)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "C:\Users\10743215\Documents\RAG\graphRAG\graphragvenv\lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Unterminated string starting at: line 37 column 28 (char 7498)
14:12:32,687 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
14:12:32,687 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 55
14:12:43,904 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:43,909 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.0. input_tokens=2202, output_tokens=641
14:12:44,101 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:44,106 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.89100000000326. input_tokens=2208, output_tokens=607
14:12:44,350 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:44,353 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.03100000001723. input_tokens=2159, output_tokens=499
14:12:44,887 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:44,894 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.921999999962281. input_tokens=2165, output_tokens=538
14:12:44,934 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:44,944 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.60999999998603. input_tokens=2106, output_tokens=574
14:12:45,339 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:45,345 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.03100000001723. input_tokens=2091, output_tokens=600
14:12:45,767 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:45,772 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.421999999962281. input_tokens=2124, output_tokens=543
14:12:46,269 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:46,275 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.10999999998603. input_tokens=2138, output_tokens=639
14:12:46,665 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:46,667 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:46,672 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.75. input_tokens=2462, output_tokens=814
14:12:46,677 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.547000000020489. input_tokens=2901, output_tokens=698
14:12:47,4 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:47,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.89100000000326. input_tokens=2387, output_tokens=571
14:12:47,116 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:47,120 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.96799999999348. input_tokens=2371, output_tokens=612
14:12:47,264 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:47,267 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.26600000000326. input_tokens=2604, output_tokens=856
14:12:48,59 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:48,64 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.047000000020489. input_tokens=4391, output_tokens=933
14:12:48,784 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:48,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.422000000020489. input_tokens=3468, output_tokens=926
14:12:49,199 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:49,205 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.922000000020489. input_tokens=2622, output_tokens=643
14:12:49,397 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:49,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 16.45299999997951. input_tokens=2312, output_tokens=682
14:12:49,792 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:49,797 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 16.70299999997951. input_tokens=2672, output_tokens=872
14:12:50,410 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:50,424 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 17.53100000001723. input_tokens=17845, output_tokens=1275
14:12:50,880 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:50,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 17.81199999997625. input_tokens=4616, output_tokens=961
14:12:51,186 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:51,194 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 18.14100000000326. input_tokens=4014, output_tokens=936
14:12:51,198 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:51,205 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 18.23499999998603. input_tokens=3515, output_tokens=1093
14:12:51,417 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:51,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 18.17200000002049. input_tokens=3472, output_tokens=808
14:12:51,506 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:51,508 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:51,512 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.561999999976251. input_tokens=2212, output_tokens=546
14:12:51,518 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.60999999998603. input_tokens=2523, output_tokens=719
14:12:52,835 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:52,848 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.172000000020489. input_tokens=2266, output_tokens=531
14:12:53,363 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:53,369 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.46799999999348. input_tokens=2294, output_tokens=628
14:12:53,383 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:53,388 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.280999999959022. input_tokens=2369, output_tokens=695
14:12:53,572 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:53,581 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 20.53200000000652. input_tokens=5408, output_tokens=1113
14:12:54,689 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:54,695 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.0. input_tokens=2565, output_tokens=603
14:12:56,152 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:56,157 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.796999999962281. input_tokens=4280, output_tokens=851
14:12:57,492 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:57,499 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.21799999999348. input_tokens=2984, output_tokens=868
14:12:57,954 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:57,962 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.187000000034459. input_tokens=2853, output_tokens=837
14:12:58,525 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:12:58,530 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.171999999962281. input_tokens=3276, output_tokens=803
14:13:05,245 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:05,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 32.07799999997951. input_tokens=4010, output_tokens=949
14:13:12,526 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:12,527 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.687999999965541. input_tokens=2086, output_tokens=413
14:13:12,712 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:12,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.969000000040978. input_tokens=2115, output_tokens=328
14:13:13,551 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:13,554 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.797000000020489. input_tokens=2102, output_tokens=457
14:13:14,500 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:14,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.73499999998603. input_tokens=2157, output_tokens=533
14:13:15,633 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:15,657 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.671999999962281. input_tokens=2165, output_tokens=510
14:13:16,107 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:16,112 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.438000000023749. input_tokens=9396, output_tokens=936
14:13:16,226 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:16,232 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.547000000020489. input_tokens=2139, output_tokens=574
14:13:16,236 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:16,244 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.545999999972992. input_tokens=2322, output_tokens=622
14:13:16,514 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:16,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.671999999962281. input_tokens=2123, output_tokens=469
14:13:17,194 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:17,207 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.422000000020489. input_tokens=2471, output_tokens=657
14:13:17,906 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:17,911 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.09299999999348. input_tokens=2153, output_tokens=600
14:13:18,607 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:18,614 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.73399999999674. input_tokens=2115, output_tokens=643
14:13:19,956 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:19,972 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.15600000001723. input_tokens=2501, output_tokens=804
14:13:21,74 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:21,86 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.094000000040978. input_tokens=2971, output_tokens=1053
14:13:21,427 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:21,474 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.610000000044238. input_tokens=2486, output_tokens=614
14:13:21,476 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:21,482 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.75. input_tokens=5804, output_tokens=1132
14:13:22,170 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:22,178 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 16.25. input_tokens=4475, output_tokens=983
14:13:22,471 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:22,476 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 16.57800000003772. input_tokens=6007, output_tokens=948
14:13:23,369 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:23,375 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 17.42099999997299. input_tokens=6944, output_tokens=943
14:13:39,395 httpx INFO HTTP Request: POST https://cognisearch.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
14:13:39,404 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 33.375. input_tokens=9116, output_tokens=1305
14:13:39,593 datashaper.workflow.workflow INFO executing verb window
14:13:39,603 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
14:13:40,26 graphrag.index.run INFO Running workflow: create_final_text_units...
14:13:40,26 graphrag.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'create_base_text_units', 'join_text_units_to_relationship_ids']
14:13:40,27 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
14:13:40,40 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
14:13:40,57 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
14:13:40,197 datashaper.workflow.workflow INFO executing verb select
14:13:40,287 datashaper.workflow.workflow INFO executing verb rename
14:13:40,562 datashaper.workflow.workflow INFO executing verb join
14:13:40,859 datashaper.workflow.workflow INFO executing verb join
14:13:41,49 datashaper.workflow.workflow INFO executing verb aggregate_override
14:13:41,144 datashaper.workflow.workflow INFO executing verb select
14:13:41,152 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
14:13:41,512 graphrag.index.run INFO Running workflow: create_base_documents...
14:13:41,528 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
14:13:41,582 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
14:13:41,734 datashaper.workflow.workflow INFO executing verb unroll
14:13:41,801 datashaper.workflow.workflow INFO executing verb select
14:13:41,878 datashaper.workflow.workflow INFO executing verb rename
14:13:42,89 datashaper.workflow.workflow INFO executing verb join
14:13:42,315 datashaper.workflow.workflow INFO executing verb aggregate_override
14:13:42,420 datashaper.workflow.workflow INFO executing verb join
14:13:42,635 datashaper.workflow.workflow INFO executing verb rename
14:13:42,913 datashaper.workflow.workflow INFO executing verb convert
14:13:43,139 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
14:13:43,788 graphrag.index.run INFO Running workflow: create_final_documents...
14:13:43,804 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
14:13:43,874 graphrag.index.run INFO read table from storage: create_base_documents.parquet
14:13:44,16 datashaper.workflow.workflow INFO executing verb rename
14:13:44,22 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
